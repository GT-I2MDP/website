<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Image et IA Multimodale</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="container">
    <header> 
      <h1>Groupe de Travail <br/>&laquo; Image et IA Multimodale<br/> pour le Diagnostic de pathologies Pulmonaires&raquo;</h1>
      <h2>GT-I<sup>2</sup>MDP du GDR-IASIS</h2>
      <h3>Karim Hammoudi, Université de Haute-Alsace, IRIMAS</h3>
      <h3>Halim Benhabiles, IMT Nord Europe, CERI SN</h3>
      <h3>Adnane Cabani, Université Rouen Normandie, ESIGELEC, IRSEEM</h3>
    </header>

    <section>
      <h2>Motivation</h2>
      <p>
        En santé de précision, de nouvelles architectures émergent régulièrement en apprentissage automatique basé image
en vue de résoudre des tâches de classification de pathologies, de localisation d’infections, de quantification de la
gravité de maladies. En particulier, ces architectures produisent de façon automatique des primitives, des indicateurs,
voire des diagnostics en vue de permettre aux radiologues et cliniciens la contre-vérification de leur analyse. Depuis
l’apparition de la COVID-19, les recherches en santé intelligente se sont intensifiées et ont conduit à la production de
diverses architectures d’analyse pathologique de type ensembliste, translationnelle et multitâche visant notamment à
faciliter les diagnostics et à diminuer les délais jusqu'à l'initiation d’un traitement. Toutefois, la nouveauté des
problématiques d’analyse pathologique abordées et les capacités limitées d’annotation et d’étiquetage des données
rendent souvent compliquée la constitution de jeux d’apprentissage statistiquement représentatifs des types
d’instances visés. Pour ces raisons, nous explorons de nouvelles pistes de recherche pour diversifier les données à
travers des approches d’augmentation, notamment superpixeliques. De plus, de nouvelles approches exploitant dans
les phases d’apprentissage des images et données de natures variées ont vu le jour comme celles basées sur
l’apprentissage multimodal ou l’apprentissage auto-supervisé (e.g. foundation model). Ces architectures à investiguer
se veulent plus génériques quant à leur capacité à traiter des données variées et peuvent même produire en sortie,
non pas un élément servant au diagnostic, mais un rapport détaillé et précis du cas pathologique analysé.
      </p>
    </section>

    <section>
      <h2>Objectifs</h2>
      <p>
        L’objectif de ce GT est de fédérer une animation scientifique initiée en 2019 de façon tripartite (IRIMAS Mulhouse,
        CNRS IEMN Lille, IRSEEM Rouen) pour le diagnostic automatisé de pathologies en imagerie médicale notamment radiologique et
        microscopique. Le GT abordera ce thème en prenant appui sur des travaux matures issus de nos projets accessibles en
        ligne SuperpixelGridMasks sur l’axe augmentation d’images e.g. 
	[<a href="https://link.springer.com/article/10.1007/s41666-022-00122-1">1</a>,
	<a href="https://www.sciencedirect.com/science/article/pii/S0031320323001814">2</a>] 
	ainsi que <a href="https://github.com/bouthainas/ViTReg-IP">ViTReg-IP</a> et 
	<a href="https://github.com/bouthainas/MViTReg-IP">MViTReg-IP</a> 
	sur l’axe approfondissement de méthodes de régression pour l’estimation de la sévérité de pathologies e.g. 
	[<a href="https://link.springer.com/article/10.1007/s10916-021-01745-4">3</a>,<a href="https://ieeexplore.ieee.org/document/10440358">4</a>,<a href="https://ieeexplore.ieee.org/document/10543042">5</a>], 
	et <a href="https://github.com/bguetarni/DLBCL-subtype">DLBCL-Subtype</a>, <a href="https://github.com/bguetarni/DLBCL-treatment-response">DLBCL-treatment-response</a> 
	sur l’axe apprentissage multimodal et transfert de connaissances de modèles de fondation pour le sous-typage de maladies et la prédiction de la réponse aux traitements e.g. [<a href="https://doi.org/10.1109/JBHI.2024.3407878">6</a>,<a href="https://doi.org/10.1007/978-3-031-77786-8_15">7</a>].
	Ce GT insufflera une dynamique autour de ces axes permettant de remonter à
        la communauté du GdR des débats et exposés en proposant des séminaires, d’une part par association aux journées
        que nous organisons avec nos laboratoires respectifs et d’autre part par l’organisation de journées au sein du GdR IASIS. Le GT produira <b>une librairie python
        diffusée en libre accès pour l’augmentation superpixelique d’images</b> ainsi qu’un <b>article collectif en lien exposant nos avancées en image et IA multimodale pour le diagnostic automatisé</b> de données radiographiques, voire d’une autre nature.
      </p>
    </section>

    <section>
      <h2>Tentative Challenge (In Construction): NoduLoC: Lung Nodule Localization Contest from Chest X-Ray Images</h2>
		<h3>Task overview</h3>
		<p>
		  Our challenge focuses on developing and improving lung nodule localization methods in Chest X-Ray images. 
		  In this challenge we focus on finding the center point of a nodule in a chest x-ray image.
			The competition is open to any team of which at least one member holds a Ph.D in computer science, biomedical engineering, or radiology.
		</p>
		<h3>Datasets</h3>
		<p>
			The competitors will be provided with a dataset of X images of frontal radiographs as JPG images along with the ground truth data represented by the pixel position annotated by at least one expert.
			We will use an external dataset as a blind test set.
		</p>
		<h3>Evaluation</h3>
		<p>
			The evaluation metrics used to determine a ranking between teams will be the mean square error of distances between the predicted point and the ground truth.
			In case there are ties, the mean absolute error will be used.
		</p>
		<h3>Submission</h3>
		<p>
			Final submissions will need to provide
			<ul>
				<li>The source code</li>
				<li>A summary of the approach</li>
				<li>The training time</li>
				<li>The inference time</li>
				<li>Hardware</li>
				<li>Number of model parameters</li>
			</ul>
		</p>
		<h3>Registration</h3>
		<p>
			To join the competition please send an email to adnan.mustafic@uha.fr containing the following information: 
		<ul>
			<li>Your teamname for the challenge</li>
			<li>The full list of participants and their affiliations</li>
		  </ul>
		</p>
	</section>
	  
<!--
    <section>
      <h2>Challenge : Défi de notation automatique de la gravité des infections pulmonaires</h2>
      <p>
	L’évaluation de la gravité des infections pulmonaires chez les patients est d’une grande importance pour le personnel médical afin de mettre en place un traitement efficace et adapté. Une méthode d’évaluation émergente repose sur l’analyse d’images biomédicales à l’aide de modèles d’intelligence artificielle. Ces modèles prennent des images en entrée et tentent de prédire un score pour chaque patient. Les scores prédits peuvent inclure : l’évaluation radiographique de l’opacité pulmonaire, l’évaluation radiographique de l’œdème pulmonaire, ou encore le score Brixia pour la gravité de la COVID-19.
      </p>	      
	<p>
	    Toute personne intéressée par des problématiques liées aux solutions d’IA émergentes est la bienvenue pour participer.
		</p>
<p>L’objectif de ce défi est de construire un modèle prenant en entrée une radiographie thoracique afin de prédire un score de gravité pour un patient donné, selon le score RALO (Radiographic Assessment of Lung Opacity). Chaque image disposera d’un score d’opacité pulmonaire et d’un score d’étendue géographique, chacun variant de 0 à 8, que l’algorithme devra prédire.</p>
<p>Les données utilisées proviendront des jeux de données <a href="https://doi.org/10.5281/zenodo.4634000">RALO</a> et <a href="https://brixia.github.io/">BrixIA</a>. Un jeu de test à l’aveugle devra être créé. Les licences des données devront être vérifiées.</p>
<p>Les modèles seront évalués à l’aide de la perte L1 (ou erreur absolue moyenne). En cas d’égalité, le coefficient de corrélation de Pearson sera utilisé. En cas de nouvelle égalité, l’erreur quadratique moyenne (MSE) sera prise en compte.</p>
<p>Le modèle fourni atteint une performance moyenne de 0,889 MAE avec un coefficient de corrélation de 0,824 pour le score GE (étendue géographique) sur le jeu de test RALO, et une MAE de 0,826 avec un coefficient de corrélation de 0,715 pour le score LO (opacité pulmonaire) du même jeu de test. Le test utilisé durant la phase de classement public est défini <a href="https://github.com/mlmed/covid-severity/blob/master/severity_utils.py">ici</a>. 
<p>Les résultats doivent être reproductibles.</p>
      
    </section>
	  
    <section>
      <h2>Plan de travail prévisionnel</h2>
      <ul>  
	<li>Mois 0 : Lancement officiel du GT</li>
	<li>Mois 1–3 : Lancement du groupe & appel à participation</li>
	<li>Mois 4–6 : Préparation technique du challenge</li>
	<li>Mois 6 : Séminaire  + dissémination du challenge</li>
	<li>Mois 11 : Collecte des soumissions & support</li>
	<li>Mois 13 : Evaluation des soumissions</li>
	<li>Mois 15 : Séminaire présentation des résultats</li>
	<li>Mois 18-24 : Finalisation et soumission de l'article</li>
	<li>Mois 24 : Séminaire Clôture du GT</li>
      </ul>
    </section>

<h2>Références</h2>
[1] K. Hammoudi, A. Cabani, B. Slika et al., 
	<i>SuperpixelGridMasks Data Augmentation: Application to Precision Health and Other Real-world Data,</i> 
	J Healthc Inform Res 6, pp 442–460, 2022. 
	doi: <a href="https://doi.org/10.1007/s41666-022-00122-1">10.1007/s41666-022-00122-1</a>
<br/><br/>
[2] F. Dornaika, D. Sun, K. Hammoudi, J. Charafeddine, A. Cabani, C. Zhang, 
    	<i>Object-centric Contour-aware Data Augmentation Using Superpixels of Varying Granularity,</i>
    	Pattern Recognition, Volume 139, 2023. 
    	doi: <a href="https://doi.org/10.1016/j.patcog.2023.109481">10.1016/j.patcog.2023.109481</a>
<br/><br/>
[3] K. Hammoudi, H. Benhabiles, M. Melkemi et al., 
	<i>Deep Learning on Chest X-ray Images to Detect and Evaluate Pneumonia Cases at the Era of COVID-19,</i> 
	J Med Syst 45, 75, 2021. 
	doi: <a href="https://doi.org/10.1007/s10916-021-01745-4">10.1007/s10916-021-01745-4</a> 
<br/><br/>
[4] B. Slika, F. Dornaika and K. Hammoudi, 
	<i>Multi-Score Prediction for Lung Infection Severity in Chest X-Ray Images,</i> 
	IEEE Transactions on Emerging Topics in Computational Intelligence, vol. 9, no. 2, pp. 2052-2058, 2025. 
	doi: <a href="https://doi.org/10.1109/TETCI.2024.3359082">10.1109/TETCI.2024.3359082</a>
<br/><br/>
[5] B. Slika, F. Dornaika, F. Bougourzi, K. Hammoudi, 
	<i>Transformer-Based Lung Infection Severity Prediction with Cross Attention and Conditional TransMix Augmentation,</i> 
	Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, Nashville, Tennessee, USA, June 2025. (to appear)
<br/><br/>
[6] B. Guetarni, F. Windal, H. Benhabiles et al., 
	<i>A Vision Transformer-Based Framework for Knowledge Transfer From Multi-Modal to Mono-Modal Lymphoma Subtyping Models,</i> 
	IEEE Journal of Biomedical and Health Informatics, vol. 28, no. 9, pp. 5562-5572, 2024. 
	doi: <a href="https://doi.org/10.1109/JBHI.2024.3407878">10.1109/JBHI.2024.3407878</a>
<br/><br/>
[7] B. Guetarni, F. Windal, H. Benhabiles et al., 
	<i>Histopathology Image Embedding Based on Foundation Models Features Aggregation for DLBCL Patient Treatment Response Prediction,</i> 
	International Workshop on Medical Optical Imaging and Virtual Microscopy Image Analysis (MICCAI workshop), LNCS Springer, pp. 150-159, 2024. 
	doi: <a href="https://doi.org/10.1007/978-3-031-77786-8_15">10.1007/978-3-031-77786-8_15</a>.
  </div>
	  -->
</body>
</html>

